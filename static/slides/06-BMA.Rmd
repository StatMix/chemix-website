---
title: "Tutorial 06 - Bayesian Model Averaging"
author: "Olivia Fan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: "./tutorials.css"
    toc: true
    toc_float: true
---

<!-- Setup -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning=FALSE,
                      message=FALSE)
```

## Topics

-   Basic ideas of Bayesian Model Averaging

-   Application of Bayesian Model Averaging using R package BAS

-   Estimation, Interpretation and Prediction

-   Advantages of Bayesian Model Averaging over all-or-none model selection

## Libraries

The R package `BAS` provides ways of carrying out BMA for linear regression, generalized linear models, and survival or event history analysis using Cox proportional hazards models. It contains functions for plotting the BMA posterior distributions of the model parameters, as well as an image plot function that provides a way of visualizing the BMA output. The functions `bas.lm` provide fast and automatic default ways of doing this for the model classes considered.

```{r}
library(BAS)
library(tidyverse)
library(broom.mixed)
```

To illustrate how BMA takes account of model uncertainty about the variables to be included in linear regression, we will be using the `nhanes` dataset where the variables are described in the file `nhanes-codebook.txt`. Load this data with the `load` function and specify the data file.

```{r}
load(file='nhanes1518.rda')
```

## Exploratory Data Analysis

We first explore the URX predictors (i.e. the ones related to phthalates concentrations), subsetting subset the dataset to include only the predictors in the weighted quantile sum module, and then filter out `NA` values:

```{r}
nhanes_URX<-nhanes1518%>%
  select(BMXBMI, URXUCR, URXCNP,URXCOP,URXECP,URXHIBP,URXMBP,URXMC1,URXMEP,URXMHBP,URXMHH)%>%
  na.omit()
```

We first start exploring the data by plotting a correlation matrix between the variables of interest. We can use the `corrplot` function within the `corrplot()` package, and adjust the style to fit our aesthetics of desire. We see that the predictors are highly correlated, especially between URXMHH and URXECP, and URXMHBP and URXMBP.

```{r}
library(corrplot)
corr_mat=cor(nhanes_URX,method="s")
corrplot(corr_mat, 
         addCoef.col = 1,    
         number.cex = 0.5) # Change font size of correlation coefficients
# other styles:
# default 
# corrplot(corr_mat) # circles
# squares, variables presented in an alphabet order
# corrplot(corr_mat, method = 'color', order = 'alphabet') # squares
# can choose different style for lower and upper triangle, can order the variable by clustering result
#corrplot.mixed(corr_mat, lower = 'shade', upper = 'pie', order = 'hclust')
```

```{r}
library(tidyverse)
df_long <- nhanes_URX %>% pivot_longer(everything())

# Plot histograms using ggplot
ggplot(df_long, aes(x = value)) +
  geom_histogram() +
  facet_wrap(~ name, scales = "free")
```

We also plot the distributions of our variables of interest involved in the model, and notice that the variables have a long tail in the original scale, which hints at log transformation which we will perform later on.

## Bayesian Model Averaging

Motivated from chemical mixtures, one way to deal with highly correlated predictors is to select variable, or select model. Traditionally, analysis often proceeds by first selecting the best model according to some criterion and then learning about the parameters given that the selected model is the underlying truth. However, this approach has potential issues: (1) We cannot quantify model uncertainty through these all-or-none selection methods. (2) There are often many modeling choices that are secondary to the main questions of interest but can still have an important effect on conclusions. An alternative is to learn the parameters for *all* candidate models and then combine the estimates according to the posterior probabilities of associated model. *Bayesian Model Averaging* (BMA) carry this model combination idea - Specifically, this is done through a parameter estimate obtained by averaging the predictions of the different models under consideration, each weighted by its model probability. The math formula below illustrate below:

Given quantity of interest $\Delta$, such as an effect size, a future observation, or utility of a course of action, then its posterior distribution of given data D is 

$$pr(M_k|D) = \frac{pr(D|M_k)pr(M_k)}{\Sigma_{l=1}^k pr(D|M_l)pr(M_l)}$$

This is an average of the posterior distributions under each of the models considered, weighted by their posterior model probability. 

There are three packages available: `BAS`, `BMS`, and `BMA`. A thorough comparison are presented in this [paper](https://www.researchgate.net/profile/Christopher-Parmeter/publication/268216833_Bayesian_model_averaging_in_R/links/54ac4c040cf2479c2ee7b14e/Bayesian-model-averaging-in-R.pdf).  In this module, we will investigate this method known as *Bayesian Model Averaging* using `BAS` package. 

## Bayesian Model Averaging for Linear Regression Models

As shown in the formula above, BMA addresses model uncertainty in a canonical regression problem, and here we consider $M_k$ to be linear regression. Suppose a linear model structure, with $y$ being the dependent variable, $\alpha_\gamma$, a constant, $\beta_\gamma$ the coefficients, and $\epsilon$ a normal IID error term with variance $\sigma^2$:
$$y=\alpha_\gamma+X_\gamma \beta_\gamma+\epsilon \hspace{1cm}\epsilon \sim N(0, \sigma^2I)$$

We fit a BMA model on the dataset using BMI as the response variable, and all of the 10 URX variables as predictor variables, after log transforming both variables: 

As seen in the EDA, we perform log transformation due to the long tail and extreme values in the original scale.

To get started, we will use `BAS` with the Zellner-Siow Cauchy prior on the coefficients.

```{r}
nhanes_URX<-log(nhanes_URX)
model <-bas.lm(BMXBMI ~ .,
  data = nhanes_URX,
  prior = "ZS-null",
  modelprior = uniform(), initprobs = "eplogp", method="MCMC",
  force.heredity = FALSE, pivot = TRUE
)
summary(model)
```

Here we specify the `ZS-null` as the prior argument, and the argument `uniform()` means that the prior distribution over the models is a uniform distribution which assigns equal probabilities to all models. The  optional argument `initprobs=eplogp` provides a way to initialize the sampling algorithm and order the variables in the tree structure that represents the model space in BAS. The eplogp option uses the Bayes factor calibration of p-values $-eplog(p)$ to provide an approximation to the marginal inclusion probability that the coefficient of each predictor is zero, using the p-values from the full model. The `force.heredity = TRUE` argument means that we force levels of a factor to enter or leave together. Pivot is logical variable to allow pivoting of columns when obtaining the OLS estimates of a model so that models that are not full rank can be fit.

From the model summary, we see that list of the top 5 models (in terms of posterior probability) with the zero-one indicators for variable inclusion. The other columns in the summary are the Bayes factor of each model to the highest probability model (hence its Bayes factor is 1), the posterior probabilities of the models (represented by `PostProbs`), the ordinary $R^2$ of the models, the Bayesian information criterion (BIC), the dimension of the models as well as the log marginal likelihood under the selected prior distribution. Each column represents a binary outcome of whether the model includes the variable or not. Here we see that the `URXHIBP` and `URXECP` are included in every single model considered, thus deemed to be important by the BMA model. On the other hand, the `URXMC1` variable is considered by only one model, therefore deemed to be insignificant by the BMA model. 

> We need to provide example on how to dig insights using the model instead of purely presenting the R coding. Read the Section 7.2 Example 2 of Bayesian Model Averaging: A Tutorial carefully. Please also read the application part of this paper carefully: [Bayesian Model Averaging: Theoretical Developments and Practical Applications](https://www.cambridge.org/core/journals/political-analysis/article/bayesian-model-averaging-theoretical-developments-and-practical-applications/3179D92A3C9353DE7E4674987C33FD28)

In R, the `image` function may be used to create an image of the model space that looks like a crossword puzzle:

```{r}
image(model, rotate=F)
```

Here, the predictors, including the intercept, are on the y-axis, while the x-axis corresponds to each different model. The red color indicates when the variable estimate is positive, the blue color indicates when the variable estimate is negative, and the beige color is the color to use when the variable is not included in the model. Here the imageplot indicates that most of the URX variables are significant in predicting the BMI level, except for `URXMC1` which is not included in all of the six models produced by BMA.

If we view the image by rows, we can see whether one variable is included in a particular model. For each variable, there are only 6 models in which it will appear. For example, we see that `URXUCR` and `URXMEP` appear in all the models. `URXMHH` appears in the top 2 models with larger posterior probabilities, but not the last 4 models.

We can also plot the posterior distributions of these coefficients to take a closer look at the distributions:

```{r}
coef.model <- coef(model)
par(mfrow=c(2,2))
# plot(coef.model, mfrow=c(3,3), ask = F)
plot(coef.model, ask = F)
```

This plot agrees with the summary table we obtained above, which shows that the posterior probability distributions of `URXMC1` and `URXCOP` have a very large point mass at 0, while the distribution of `URXUCR` and `URXMEP` have relatively small mass at 0. There is a slighly little tip at 0 for the variable `URXUCR`, indicating that the posterior inclusion probability of `URXECP` is not exactly 1. However, since the probability mass for `URXUCR` to be 0 is so small, that we are almost certain that `URXECP` should be included under Bayesian model averaging.

## Bayesian Model Diagnostics

```{r}
plot(model, ask = F)
```

```{r}
diagnostics(model, type = "pip", pch = 16) 
```

```{r}
plot(confint(coef.model),estimator = "HPM") # also look into this
```

## Bayesian Model Predictions

With the `predict` function, we can understand uncertainty besides classification, taking a look at the predictive probabilities for the two class classification problem:


## Bayesian Model Predictions with Model Selection

`BAS` has methods defined to return fitted values, namely `fitted`, using the observed design matrix and predictions at either the observed data or potentially new values, predict, as with linear regressions

```{r}
muhat.BMA <- fitted(model, estimator = "BMA")
BMA <- predict(model, estimator = "BMA")

# predict has additional slots for fitted values under BMA, predictions under each model
names(BMA)
```

We plot the two sets of fitted values:

```{r}
par(mar = c(9, 9, 3, 3))
plot(muhat.BMA, BMA$fit,
  pch = 16,
  xlab = expression(hat(mu[i])), ylab = expression(hat(Y[i]))
)
abline(0, 1)
```

We see that they are in perfect agreement, which is always true as the posterior mean for the regression mean function at point $x$ is the perfect expected posterior value for $Y$ at $x$.

In addition to using BMA, we can use the posterior means under model selection. This corresponds to a decision rule that combines estimation and selection. `BAS` currently implements the following options:

### Highest Probability Model

```{r}
HPM <- predict(model, estimator = "HPM")

# show the indices of variables in the best model where 0 is the intercept
HPM$bestmodel
```

Now we explore a little more interpretable version with names:

```{r}
variable.names(HPM)
```

### Median Probability Model

```{r}
MPM <- predict(model, estimator = "MPM")
variable.names(MPM)
```

This is the model where all predictors have an inclusion probability greater than or equal to 0.5. This coincides with the HPM if the predictors are all mutually orthogonal, and in this case is the best predictive model under squared error loss.

Note that we can also extract the best model from the attribute in the fitted values as well.

### Best Predictive Model

In general, the HPM or MPM are not the best predictive models, which from a Bayesian decision theory perspective would be the model that is closest to BMA predictions under squared error loss.

```{r}
BPM <- predict(model, estimator = "BPM")
variable.names(BPM)
```

Now we use ggpairs to see how these models compare:

```{r}
library(GGally)
GGally::ggpairs(data.frame(
  HPM = as.vector(HPM$fit), # this used predict so we need to extract fitted values
  MPM = as.vector(MPM$fit), # this used fitted
  BPM = as.vector(BPM$fit), # this used fitted
  BMA = as.vector(BMA$fit)
)) # this used predict
```
Using the `se.fit = TRUE` option with `predict` we can also calculate standard deviations for prediction or for the mean and use this as input for the `confint` function for the prediction object. Since there are many predictions, here we slice 15 samples and observe their confidence intervals:

```{r}
BPM <- predict(model, estimator = "BPM", se.fit = TRUE)
model.fit <- confint(BPM, parm = "mean")
model.pred <- confint(BPM, parm = "pred")
# take 15 samples
sample<-model.fit[1:15,]
class(sample) <- "confint.bas"
plot(sample)
```


```{r}
sample<-model.pred[1:15,]
class(sample) <- "confint.bas"
plot(sample)
```

## Prior Selection

BAS uses a model formula similar to lm to specify the full model with all of the potential predictors. Here we are using the shorthand . to indicate that all remaining variables in the data frame provided by the data argument. Prior selection is a critical step in Bayesian model averaging (BMA) as it determines the weights assigned to each model in the model space. The choice of prior distribution for the model parameters can significantly impact the BMA results. A well-informed prior can help avoid overfitting, reduce uncertainty, and improve model selection. However, selecting an appropriate prior can be challenging as it requires balancing between being informative enough to guide the model towards plausible solutions and being uninformative enough to avoid biasing the results. Prior elicitation techniques such as expert opinion, empirical data, and sensitivity analysis can be employed to guide the choice of priors. Overall, careful prior selection is crucial for obtaining reliable and accurate BMA results.
Different prior distributions on the regression coefficients may be specified using the prior argument, and include

- “BIC”
- “AIC
- "g-prior", Zellner's g prior where 'g' is specified using the argument 'alpha'
- "hyper-g", a mixture of g-priors where the prior on g/(1+g) is a Beta(1, alpha/2) as in Liang et al (2008). This uses the Cephes library for evaluation of the marginal likelihoods and may be numerically unstable for large n or R2 close to 1. Default choice of alpha is 3.
- "hyper-g-laplace", Same as above but using a Laplace approximation to integrate over the prior on g.
- "hyper-g-n", a mixture of g-priors that where u = g/n and u ~ Beta(1, alpha/2) to provide consistency when the null model is true.
- "JZS" Jeffreys-Zellner-Siow prior which uses the Jeffreys prior on sigma and the Zellner-Siow Cauchy prior on the coefficients. The optional parameter 'alpha' can be used to control the squared scale of the prior, where the default is alpha=1. Setting 'alpha' is equal to rscale^2 in the BayesFactor package of Morey. This uses QUADMATH for numerical integration of g.
- "ZS-null", a Laplace approximation to the 'JZS' prior for integration of g. alpha = 1 only. We recommend using 'JZS' for accuracy and compatibility with the BayesFactor package, although it is slower.
- "ZS-full" (to be deprecated)
- "EB-local", use the MLE of g from the marginal likelihood within each model
- "EB-global" uses an EM algorithm to find a common or global estimate of g, averaged over all models. When it is not possible to enumerate all models, the EM algorithm uses only the models sampled under EB-local.

Here we explore the model fitted under another prior, the g-prior to investigate how the prior selection affects the model output:

```{r}
g_model <-bas.lm(BMXBMI ~ .,
  data = nhanes_URX,
  prior = "g-prior",
  modelprior = uniform(), initprobs = "eplogp", method="MCMC",
  force.heredity = FALSE, pivot = TRUE
)
summary(g_model)
```

```{r}
coef.gmodel <- coef(g_model)
par(mfrow=c(2,2))
# plot(coef.model, mfrow=c(3,3), ask = F)
plot(coef.gmodel, ask = F)
```

Comparing this model output with the previous model output under the ZS-null prior, we notice that although the ZS-null prior model considers the `URXECP` predictor to be most important with an inclusion probability of 1.00, the g-prior model considers the `URXHIBP` predictor to be important with an inclusion probability of 0.9999. However, URXUCR, URXCNP, URXECP, URXHIBP, URXMBP and URXMEP were deemed important by both models. While the predictors have generally similar degrees of importance in both models, it is also worth noting that the posterior distributions of the URX variables have slightly different shapes under the two different priors.

## Why Bayesian Model Averaging? Advantages

### Model Uncertainty

-   It is important to take account of model uncertainty about statistical structure when making inferences. Oftentimes, there is remaining uncertainty not only about parameters, but also about the underlying true model. In this case, a Bayesian analysis allows one to take into account not only uncertainty about the parameters given a particular model, but also uncertainty across all models combined.

### Simultaneous Scenarios

-   Allows users to incorporate several competing models in the estimation process. In theory, BMA provides better average predictive performance than any single model that could be selected. BMA avoids the all-or-nothing mentality that is associated with classical hypothesis testing, in which a model is either accepted or rejected wholesale. In contrast, BMA retains all model uncertainty until the final inference stage, which may or may not feature a discrete decision.

### Model Misspecification

-   BMA is relatively robust to model misspecification. If one does select a single model, then one had better be sure of being correct. With BMA, a range of rival models contribute to estimates and predictions, and chances are that one of the models in the set is at least approximately correct.

### References

https://www.jstor.org/stable/2676803?seq=3#metadata_info_tab_contents