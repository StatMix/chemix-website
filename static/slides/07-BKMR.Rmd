---
title: "Work in progress: Bayesian Kernel Machine Regression"
author: "Bradley Bowen"
date: "Last Updated `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: "./tutorials.css"
    toc: true
    toc_float: true
---

## Introduction

Often the case with health data, mixtures may have non-linear relationships with the outcome variable, meaning that standard additive models may not be best suited. Working with highly correlated exposures and complex interaction effects with previous models could potentially lead to inconsistent estimates. In this tutorial, we will explore Bayesian Kernel Machine Regression (BKMR) which allows for increased flexibility for complex relationships between the predictor and outcome variables.

Kernel Machine Regression provides a more flexible approach by using a kernel. Kernels in regression are beneficial as they provide an estimation of the relationship between the predictors and outcome without knowing the form (linear, logistic, exponential, etc). This means that the kernel is a non-parametric technique. In order to determine the best fit between the predictor variables and outcome of interest, the kernel weights data points that are close in distance to outcome higher, and points that have a greater distance lower. This method allows the regression model to better fit the data and account for complex relationships between variables.

Additionally, the Bayesian Kernel Machine Regression integrates Kernel Machine Regression in a Bayesian framework, placing priors on model parameters, providing uncertainty quantification through the posterior, and allowing for flexibility such as hierarchical variable selection.

## Preparation

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(ggcorrplot)
library(corrplot)
```

To illustrate how BKMR empowers modeling of highly correlated predictors, we will use the `nhanes` dataset where the variables are described in the file `nhanes-codebook.txt`. Load this data with the `load` function and specify the data file.

```{r}
load(file='nhanes1518.rda')
```

We first explore the URX predictors (i.e. the ones related to phthalates concentrations), subsetting subset the dataset to include only the predictors in the weighted quantile sum module, and then filter out `NA` values:

```{r}
nhanes<-nhanes1518 |>
  select(BMXBMI, URXUCR, URXCNP,URXCOP,URXECP,URXHIBP,URXMBP,URXMC1,URXMEP,URXMHBP,URXMHH,RIDAGEYR)|>
  na.omit()|>
  mutate(BMXBMI = log(BMXBMI))
nhanes_URX<-nhanes1518 |>
  select(BMXBMI, URXUCR, URXCNP,URXCOP,URXECP,URXHIBP,URXMBP,URXMC1,URXMEP,URXMHBP,URXMHH)|>
  na.omit()|>
  mutate(BMXBMI = log(BMXBMI))
```

We first start exploring the data by plotting a correlation matrix between the variables of interest. We can use the `corrplot` function within the `corrplot()` package, and adjust the style to fit our aesthetics of desire. We see that the predictors are highly correlated, especially between URXMHH and URXECP, and URXMHBP and URXMBP:

```{r}
corr_mat=cor(nhanes_URX,method="s")
corrplot(corr_mat, # colorful number
         addCoef.col = 1,    # Change font size of correlation coefficients
         number.cex = 0.5) 
```


## Bayesian Kernel Machine Regression

Bayesian Kernel Machine Regression (BKMR) model the relationship between outcome and variables using two parts: a nonparametric function $h(\cdot)$ and linear function.

$$g(E(Y)) = h(X_1,\dots,X_k)+\beta Z$$

where $g(\cdot)$ is a link function, $h(\cdot)$ is a nonparametric function capturing the nonlinear relationship between chemical mixtures $(X_1,\dots,X_k)$ and outcome, and $Z$ represent other variables which may have linear relationship with outcome. 

The nonparametric function $h(\cdot)$ is highly flexible, and usually represented using kernel function. Let $\bf{X} = (X_1,\dots,X_k)$ representing the vector of chemical mixtures, we have the kernel representation of $h(\bf{X})$:

$$h(\bf{X}) = \sum_{i=1}^n K(X_i,X) \alpha_i$$

where $K(X,X')$ is a function measures the similarity of $X$ and $X'$, $\alpha_i$'s are coefficients. The outcome corresponding to $X$ are weighted by similarity of $X$ to the data points $\{X_i,i = 1,\dots,n\}$, data points that are more similar/ closer to $X$ will plays more important role in outcome estimation. A common choice is a Gaussian kernel 

$$K(X,X') = exp\{-\sum_{k=1}^K(X_k-X_k')^2/\rho\}$$.

The BKMR can also allow for variable selection by slightly modifying the kernel:

$$K(X,X';r) = exp\{-\sum_{k=1}^Kr_k(X_k-X_k')^2\}$$

where $r_k$ are non-negative values, with a "slab-and-spike" prior. If $r_k=0$, the variable $X_k$ are excluded from the model. 

### Model Fitting

Similar to previous tutorials, we are interested in the research question: predicting log BMI using phthalate measurements from urine samples for individuals above 18 years of age. We assume the age has linear relationship to logBMI.

```{r}
y<-nhanes$BMXBMI # bmi
Z <- nhanes |> select(-BMXBMI, -URXMC1, -URXMEP, -RIDAGEYR) # chemical mixtures
# group 1: URXMBP, URXMIB, URXMC1, URXMEP, URXMZP
# group 2: URXECP, URXMHH, URXMOH, URXMHP
X <- nhanes |> select(RIDAGEYR)
```

To fit the BKMR model, we use the `kmbayes` function in R package `bkmr`. 

```{r}
#install.packages("bkmr")
library(bkmr)
```

In the model:

-   `y` is a vector of the response

-   `Z` is the matrix containing chemical mixtures (variables with nonlinear relationship to outcome)

-   `X` is the matrix containing other covariates with linear relationship to outcome

-   `iter` number of iterations of the MCMC sampler

-   `varsel`, whether to conduct variable selection on the predictors $Z$.

-   `verbose`, printing the details during modeling fitting


```{r}
set.seed(111)
fitkm_corr <- bkmr::kmbayes(y = y, Z = Z, X = X, iter = 5000, varsel = FALSE, verbose = FALSE)
```

### Model Interpretation and Inference

```{r}
summary(fitkm_corr)
```

### Model Prediction

### Model Evaluation

Below we can view a summary of the model:



Below, we can visualize the general trace of the Markov Chain Monte Carlo method for the samples. This graphs the beta parameter used in the BKMR model.

```{r}
TracePlot(fit = fitkm_corr, par = "beta")
```

Next, we can estimate posterior inclusion probabilities (PIP), which provides the probability that a given predictor will be used in the model. As demonstrated below, #NEED TO CHECK!! URXUCR, URXCOP, URXMBP, URXMC1, URXMEP, and URXMHH are most likely not to be included in the model.

```{r}
ExtractPIPs(fitkm_corr)
```

Additionally, it is beneficial to examine the exposure-response function created by the model. With Z, the matrix containing exposures, h(z) models how the chemical mixtures influence the outcome variable (log(BMI)). This function allows us to account for non-linear relationships as well as potential interactions.

The BKMR package can estimate h(z) using three methods:

1.  Primarily, it can average estimates from the model to quickly produce h(z). This method uses the posterior means and variances to estimate the function and is very efficient. Can be completed using method = "approx".

2.  The second approach also uses the mean and variance, but averages the posterior mean and variance samples. This method produces an unbiased estimates, but large datasets, the process can take an extended period to complete. For

3.  The final method takes many samples from the posterior distribution of h(z), creating a full posterior distribution of h(z). This method provides an unbiased estimate of the posterior.

The three methods are demonstrated below using the median values of the Phalates and Phytoestrogens from the NHANES dataset.

```{r}
med <- apply(Z, 2, median)

Znew <- matrix(med, nrow = 1)

h_est1 <- ComputePostmeanHnew(fitkm_corr, Znew = Znew, method = "approx")
h_est2 <- ComputePostmeanHnew(fitkm_corr, Znew = Znew, method = "exact")
set.seed(111)

samps3 <- SamplePred(fitkm_corr, Znew = Znew, Xnew = cbind(0))

compare <- data.frame(
  method = c(1:3),
  post_mean = c(h_est1$postmean, h_est2$postmean, mean(samps3)),
  post_sd = c(sqrt(h_est1$postvar), sqrt(h_est2$postvar), sd(samps3))
)

print(compare)
```

As demonstrated above, both the second and third methods produced similar posterior means. However, the first "approximation" method differed slightly from the remaining approaches.

Summary statistics of the exposure-response function h(z) can be also examined and visualized. For example, we can examine how each phthalate contributes to the outcome BMI by comparing the effect at different percentiles while fixing the other variables to specified percentiles. In this example, we examine how the chemical mixtures differ at the 25th, 50th, and 75th percentile. The built-in `SingVarRiskSummaries` function can be used along with `qs.diff` which indicates which quantiles are being compared. Finally, the `q.fixed` argument allows the user to specify what percentiles to fix the other variables.

```{r}

Z<-as.matrix(Z)

X<-as.matrix(X)

```

```{r}

d2 <- SimData(n = 100, M = 4, Zgen = "corr", sigsq.true = 2.2)
print(d2)

risks.singvar <- SingVarRiskSummaries(fit = fitkm_corr, y = y, Z = Z, X = X, 
                                      qs.diff = c(0.25, 0.75), 
                                      q.fixed = c(0.25, 0.50, 0.75),
                                      method = "exact")
risks.singvar
```

In this example —– interpretation

## Heirarchical Selection

One of the appeals of BKMR regression is the ability to use hierarchical variable selection. This method assesses which variables are critical to the model by using grouping. Primarily, the chemical exposures are grouped, often by their relationships with other exposures or by using prior knowledge. Each exposure in the Z matrix can be assigned to a group by using `groups = c(1,1,2,2)` where the first two variables in Z are assigned to group 1, while the remaining variables are placed in group 2. If the variables are not manually grouped, there is an option for component wise selection where variables are evaluated on an individual basis (`varsel = TRUE`). An additional chemical exposure was included in this example to demonstrate correlation between exposures for grouping purposes. Both methods are demonstrated below:

```{r}
nhanes_URX_new<-nhanes1518 |>
  select(BMXBMI,RIDAGEYR, URXMBP, URXMIB, URXMC1, URXMEP, URXMZP, URXECP, URXMHH, URXMOH, URXMHP)|>
  na.omit()|>
  mutate(BMXBMI = log(BMXBMI))

```

To understand which variables should be grouped, a correlation matrix is utilized to examine each variable's relationship:

```{r}
corr_mat=cor(nhanes_URX_new,method="s")
corrplot(corr_mat, # colorful number
         addCoef.col = 1,    # Change font size of correlation coefficients
         number.cex = 0.5) 
```

Based on the correlations, we place the non-correlated variables in group 1: URXMBP, URXMIB, URXMC1, URXMEP, URXMZP.

Higly correlated variables are included in group 2: URXECP, URXMHH, URXMOH, URXMHP.

```{r}
y_final<-nhanes_URX_new$BMXBMI # bmi
Z_final <- nhanes_URX_new |> select(-BMXBMI, -RIDAGEYR) # chemical mixtures
X_final <- nhanes_URX_new |> select(RIDAGEYR)

```

```{r}

fitkm_corr <- kmbayes(y = y_final, Z = Z_final, X = X_final, iter = 10, varsel = TRUE, verbose = FALSE)
fitkm_hier <- kmbayes(y = y_final, Z = Z_final, X = X_final, iter = 10, varsel = TRUE, 
                      groups = c(#NEED TO CHANGE), verbose = FALSE)
# group 1: URXMBP, URXMIB, URXMC1, URXMEP, URXMZP
# group 2: URXECP, URXMHH, URXMOH, URXMHP
```

We can contrast the posterior inclusion probabilities from the two models:

Where the exposures were grouped:

```{r}
ExtractPIPs(fitkm_corr)
```

\
For grouped exposures:

```{r}
ExtractPIPs(fitkm_hier)

```

## Changing BKMR Parameters

An additional features of the BKMR package is that the tuning parameters for the fitting algorithm can be manually adjusted. The model uses the Markov chain Monte Carlo method and also uses Gibbs steps for updating the parameters. The following parameters can be adjusted:

| Parameter          | Parameter Call              | Uses                                       | Description/Notes                                                                  |
|--------------|--------------|--------------|------------------------------|
| $$                 
    \sigma^2         
    $$               | `a.sigsq`, `b.sigsq`        | Should be used with gaussian distributions | Described as the "shape/rate" of a gamma prior                                     |
| $$                 
    \lambda          
    $$               | `mu.lambda`, `sigma.lambda` |                                            | For gamma priors, it is mean and standard deviation                                |
| $$                 
    r_m              
    $$               | `r.prior`                   | Can be used with all models                | Specifies the prior distributions - options include “gamma”, “invunif”, and “unif” |
| $$                 
    \pi              
    $$               | `a.p0`, `b.p0`              | Should be used when `varsel = TRUE`        |                                                                                    |

Additional options can be found at the following link:

<https://jenfb.github.io/bkmr/overview.html>

## Resources:

<https://jenfb.github.io/bkmr/overview.html>
